{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn as sklearn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segmentWords(s): \n",
    "    return s.split()\n",
    "\n",
    "def readFile(fileName):\n",
    "    # Function for reading file\n",
    "    # input: filename as string\n",
    "    # output: contents of file as list containing single words\n",
    "    contents = []\n",
    "    f = open(fileName)\n",
    "    for line in f:\n",
    "        contents.append(line)\n",
    "    f.close()\n",
    "    result = segmentWords('\\n'.join(contents))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv000_29416.txt\n",
      "825\n",
      "cv000_29590.txt\n",
      "802\n"
     ]
    }
   ],
   "source": [
    "for c in os.listdir(\"data_training\"):\n",
    "    directory = \"data_training/\" + c\n",
    "    for file in os.listdir(directory):\n",
    "        print(file)\n",
    "        words = readFile(directory + \"/\" + file)\n",
    "        print(len(words))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"data_training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Dataframe containing the counts of each word in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = []\n",
    "\n",
    "for c in os.listdir(\"data_training\"):\n",
    "    directory = \"data_training/\" + c\n",
    "    for file in os.listdir(directory):\n",
    "        words = readFile(directory + \"/\" + file)\n",
    "        e = {x:words.count(x) for x in words}\n",
    "        #e['__FileID__'] = file\n",
    "        e['__CLASS__'] = c\n",
    "        d.append(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe from d - make sure to fill all the nan values with zeros.\n",
    "\n",
    "References:\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(d)\n",
    "dataframe = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into training and validation set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Sample 80% of your dataframe to be the training data\n",
    "\n",
    "* Let the remaining 20% be the validation data (you can filter out the indicies of the original dataframe that weren't selected for the training data)\n",
    "\n",
    "References:\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sample.html\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training_data = dataframe.sample(frac = 0.8)#.drop(labels = ['__FileID__'],axis = 1)\n",
    "validation_data = dataframe.drop(labels =training_data.index, axis = 0)#.drop(labels = ['__CLASS__'],axis = 1)\n",
    "\n",
    "\n",
    "#training_data,validation_data = train_test_split(dataframe.values, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split the dataframe for both training and validation data into x and y dataframes - where y contains the labels and x contains the words\n",
    "\n",
    "References:\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_training_data = training_data.drop(labels = '__CLASS__',axis = 1)\n",
    "y_training_data = training_data['__CLASS__']\n",
    "x_validation_data = validation_data.drop(labels = '__CLASS__',axis = 1)\n",
    "y_validation_data = validation_data['__CLASS__']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Logistic Regression\n",
    "* Use sklearn's linear_model.LogisticRegression() to create your model.\n",
    "* Fit the data and labels with your model.\n",
    "* Score your model with the same data and labels.\n",
    "\n",
    "References:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of Logistic Regression using default regularization term:  0.840625\n"
     ]
    }
   ],
   "source": [
    "#using default regularization term\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic = LogisticRegression()\n",
    "my_logistic_reg = logistic.fit(x_training_data,y_training_data)\n",
    "print('Score of Logistic Regression using default regularization term: ',my_logistic_reg.score(x_validation_data,y_validation_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am not overfitting, a score of 0.85 is really good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of Logistic Regression using customized regularization term and newton-cg method:  0.834375\n"
     ]
    }
   ],
   "source": [
    "#using customized regularization term and methodology\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic = LogisticRegression(C = 1e6)\n",
    "my_logistic_reg = logistic.fit(x_training_data,y_training_data)\n",
    "print('Score of Logistic Regression using customized regularization term and newton-cg method: ',my_logistic_reg.score(x_validation_data,y_validation_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection\n",
    "* In the backward stepsize selection method, you can remove coefficients and the corresponding x columns, where the coefficient is more than a particular amount away from the mean - you can choose how far from the mean is reasonable.\n",
    "\n",
    "References:\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sample.html\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.where.html\n",
    "https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.std.html\n",
    "https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.mean.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did you select which features to remove? Why did that reduce overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u0005               0.027940\n",
       "\u0013earth          0.027940\n",
       "\u0013goodies        0.027940\n",
       "\u0013if             0.027940\n",
       "\u0013ripley         0.027940\n",
       "\u0013suspend        0.027940\n",
       "\u0013they           0.027940\n",
       "\u0013white\u0014         0.027940\n",
       "\u0014               0.083762\n",
       "\u0016               0.284890\n",
       "!               2.001591\n",
       "\"              10.548344\n",
       "#               0.027940\n",
       "#05425          0.027940\n",
       "#1              0.092435\n",
       "#13             0.000000\n",
       "#2              0.083674\n",
       "#3              0.027940\n",
       "#5              0.027940\n",
       "#6              0.027940\n",
       "#8              0.027940\n",
       "#9              0.027940\n",
       "#@%$^           0.027940\n",
       "$1              0.055814\n",
       "$10             0.088167\n",
       "$100            0.088042\n",
       "$1000           0.039498\n",
       "$100m           0.000000\n",
       "$11             0.027940\n",
       "$115            0.000000\n",
       "                 ...    \n",
       "zoo-like        0.000000\n",
       "zookeeper       0.027940\n",
       "zoolander       0.000000\n",
       "zoolander's     0.000000\n",
       "zoologist       0.048356\n",
       "zoom            0.027940\n",
       "zoom-in's       0.027940\n",
       "zoom-ins        0.000000\n",
       "zoom-out        0.027940\n",
       "zoom-outs       0.000000\n",
       "zooming         0.039498\n",
       "zooms           0.108025\n",
       "zoot            0.062456\n",
       "zorg            0.027940\n",
       "zorro           0.147770\n",
       "zorro's         0.027940\n",
       "zsigmond        0.027940\n",
       "zucker          0.142308\n",
       "zuehlke         0.000000\n",
       "zuko            0.027940\n",
       "zukovsky        0.027940\n",
       "zundel          0.055880\n",
       "zurg's          0.000000\n",
       "zweibel         0.027940\n",
       "zwick           0.133863\n",
       "zwick's         0.068394\n",
       "zwigoff's       0.039498\n",
       "zycie           0.027940\n",
       "zycie'          0.027940\n",
       "|               0.027940\n",
       "Length: 45671, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(x_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3640881445395468"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(np.mean(x_training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_col = {}\n",
    "for col_name in x_training_data:\n",
    "    temp = np.mean(x_training_data[col_name])\n",
    "    if temp > .02:\n",
    "        n_col[col_name] = x_training_data[col_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 45671)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 3090)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(n_col).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Decision Tree\n",
    "\n",
    "* Initialize your model as a decision tree with sklearn.\n",
    "* Fit the data and labels to the model.\n",
    "\n",
    "References:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of default tree is: 0.628125\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "decision_tree = clf.fit(x_training_data,y_training_data)\n",
    "print('The accuracy of default tree is:', decision_tree.score(x_validation_data,y_validation_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing Parameters\n",
    "* To test out which value is optimal for a particular parameter, you can either loop through various values or look into sklearn.model_selection.GridSearchCV\n",
    "\n",
    "References:\n",
    "\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81875\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "svc = svm.SVC(C=1, kernel='linear')\n",
    "svc_fit = svc.fit(x_training_data,y_training_data)\n",
    "svc_score = svc_fit.score(x_validation_data,y_validation_data)\n",
    "print(svc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_fit = svm.SVC(C=10, kernel='rbf', gamma=0.001).fit(x_training_data,y_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72187500000000004"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_fit.score(x_validation_data,y_validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did you choose which parameters to change and what value to give to them? Feel free to show a plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is a single decision tree so prone to overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A single decision tree is prone to overfitting because the data we put in is random and contain many noise. By executing multiple trials over different trees (of the same data), we can ensure to reduce those noise and produce the true result.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Random Forest\n",
    "\n",
    "* Use sklearn's ensemble.RandomForestClassifier() to create your model.\n",
    "* Fit the data and labels with your model.\n",
    "* Score your model with the same data and labels.\n",
    "\n",
    "References:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56874999999999998"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "my_forest = clf.fit(x_training_data,y_training_data)\n",
    "my_forest.score(x_validation_data,y_validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What parameters did you choose to change and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does a random forest classifier prevent overfitting better than a single decision tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
